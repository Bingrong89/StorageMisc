{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import math\n",
    "from random import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image arrays only when needed, too much memory to load everything on initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PASCALVOC(Dataset):\n",
    "    def __init__(self,textfile =\"train_val.txt\",transform = None):\n",
    "       # assert Path(rootfolder).exists(), \"%s is an invalid path\"%rootfolder\n",
    "\n",
    "        self.classes = ('__background__','aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                         'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                         'cow', 'diningtable', 'dog', 'horse',\n",
    "                         'motorbike', 'person', 'pottedplant',\n",
    "                         'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "        \n",
    "        self.sizes = (645,429,285)\n",
    "        self.all_img_names = []      \n",
    "        \n",
    "        self.rootfolder = \"C:\\\\Users\\\\bing.DEFIDE\\\\Documents\\\\VOCtrainval_11-May-2012\\\\VOCdevkit\\\\VOC2012\"\n",
    "\n",
    "        listofimages = \"C:\\\\Users\\\\bing.DEFIDE\\\\Documents\\\\VOCtrainval_11-May-2012\\\\VOCdevkit\\\\VOC2012\\\\ImageSets\\\\Main\\\\\" + textfile\n",
    "        \n",
    "        file = open(listofimages,\"r\")\n",
    "        for line in file:\n",
    "            self.all_img_names.append((line.split(\" \"))[0])  \n",
    "        file.close()\n",
    "\n",
    "            \n",
    "    def __getitem__(self,x):\n",
    "        imgname = self.all_img_names[x]\n",
    "        imagepath = self.rootfolder+ \"\\\\JPEGImages\\\\\" + imgname + \".jpg\"\n",
    "        annopath =  self.rootfolder+ \"\\\\Annotations\\\\\" + imgname + \".xml\"\n",
    "        \n",
    "        img = cv2.imread(imagepath.strip())\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        resize_shape = self.eulc_dist(img,imgname)\n",
    "        img = cv2.resize(img,(resize_shape,resize_shape))\n",
    "        img = torch.from_numpy(img).type(\"torch.FloatTensor\")\n",
    "        \n",
    "        stepone = ET.parse(annopath.strip())\n",
    "        steptwo = stepone.findall('object')\n",
    "        stepthree = steptwo[0].find('name')\n",
    "        label = stepthree.text\n",
    "        label = self.classes.index(label)\n",
    "\n",
    "        return (img,label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_img_names)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\"\n",
    "    \n",
    "    def eulc_dist(self,img,imgname): #calc eulc dist and return the size to reshape to\n",
    "        all_dist = []\n",
    "        for x in self.sizes:\n",
    "            vert_dist =  x - img.shape[0] \n",
    "            hori_dist = x - img.shape[1]\n",
    "            dist = math.sqrt((vert_dist*vert_dist) + (hori_dist*hori_dist))\n",
    "            all_dist.append(dist)\n",
    "        \n",
    "     #   if len(set(all_dist)) != len(self.sizes): #incase two exact same euclidean distances, which actually exists in pascal voc.. image res 314,400, equiv dist from 429 and 285\n",
    "      #      raise Exception(imgname + \" has two same euclidean distances computed\")\n",
    "        #in the event of equiv eucl dist, favor the larger number for now\n",
    "        idx_of_smallest = all_dist.index(min(all_dist))\n",
    "        return self.sizes[idx_of_smallest]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_RandomSampler(Sampler):\n",
    "    def __init__(self,data_src):\n",
    "        self.data_src = data_src\n",
    "        \n",
    "        self.list645 = []\n",
    "        self.list429 = []\n",
    "        self.list285 = []\n",
    "        for x in range(len(self.data_src)):\n",
    "            if self.data_src[x][0].shape[1] == 645:\n",
    "                self.list645.append(x)\n",
    "            \n",
    "            elif self.data_src[x][0].shape[1] == 429:\n",
    "                self.list429.append(x)\n",
    "            \n",
    "            elif self.data_src[x][0].shape[1] == 285:\n",
    "                self.list285.append(x) \n",
    "                \n",
    "        self.len645 = len(self.list645)\n",
    "        self.len429 = len(self.list429)\n",
    "        self.len285 = len(self.list285)      \n",
    "\n",
    "    def __iter__(self):\n",
    "#Shuffling done at iter, so every epoch gets a new shuffled list when iter is called\n",
    "        self.finallist =[]\n",
    "        if self.len645 != 0:\n",
    "            shuffle(self.list645)\n",
    "            self.finallist.extend(self.list645)\n",
    "        if self.len429 != 0:\n",
    "            shuffle(self.list429)\n",
    "            self.finallist.extend(self.list429)\n",
    "        if self.len285 !=0:\n",
    "            shuffle(self.list285)\n",
    "            self.finallist.extend(self.list285)                \n",
    "        \n",
    "        return iter(self.finallist)\n",
    "    def __len__(self):\n",
    "        return len(self.data_src)\n",
    "        \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_BatchSampler(Sampler):\n",
    "    def __init__(self,sampler,batch_size,drop_last = True):\n",
    "    #    if not isinstance(sampler, Sampler):\n",
    "     #       raise ValueError(\"sampler should be an instance of \"\n",
    "        #                     \"torch.utils.data.Sampler, but got sampler={}\"\n",
    "       #                      .format(sampler))\n",
    "     #   if not isinstance(batch_size, _int_classes) or isinstance(batch_size, bool) or \\\n",
    "      #          batch_size <= 0:\n",
    "        if not isinstance(batch_size, int) or batch_size <= 0:\n",
    "            raise ValueError(\"batch_size should be a positive integral value, \"\n",
    "                             \"but got batch_size={}\".format(batch_size))\n",
    "            \n",
    "        if drop_last != True:\n",
    "            raise Exception(\"drop_last input={} is invalid. Only drop_last = True is implemented for this function\".format(drop_last))\n",
    "        self.sampler = sampler\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        self.len645 = self.sampler.len645\n",
    "        self.len429 = self.sampler.len429\n",
    "        self.len285 = self.sampler.len285\n",
    "\n",
    "        \n",
    "    def __iter__(self):\n",
    "        batch =[]\n",
    "        #slicing the list is probably easier and cleaner though and shouldnt take much memory\n",
    "        for count,value in enumerate(self.sampler):       \n",
    "            if count<self.len645:\n",
    "                batch.append(value)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch=[]\n",
    "            elif count == self.len645-1:\n",
    "                batch.append(value)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch =[]\n",
    "                else:\n",
    "                    batch = []\n",
    "                    continue\n",
    "            \n",
    "            elif self.len645<=count< self.len429 -1:\n",
    "                batch.append(value)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch =[]\n",
    "            elif count == self.len429 -1:\n",
    "                batch.append(value)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch =[]\n",
    "                else:\n",
    "                    batch =[]\n",
    "                    continue\n",
    "            \n",
    "            elif count>= self.len285:\n",
    "                batch.append(value)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch = []\n",
    "    \n",
    "\n",
    "    def __len__(self): \n",
    "        if self.drop_last:\n",
    "            length = (self.len645//self.batch_size) + (self.len429//self.batch_size) + (self.len285//self.batch_size)\n",
    "            return length\n",
    "        else: #not gonna use this option, not modifying\n",
    "            raise Exception(\"drop_last == False is not implemented for this function\")\n",
    "            #return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
